import { interviewAnswers, type InterviewAnswer } from './interview-answers'
import type { Locale } from '@/i18n/dictionaries'

const categoryMap: Record<Locale, Record<string, string>> = {
  tr: {},
  en: {
    'Planlama': 'Planning',
    'Müşteri': 'Client',
    'Takım': 'Team',
    'Risk': 'Risk',
    'Teknik': 'Technical',
    'Süreç': 'Process',
    'Ürün': 'Product',
  },
  ru: {
    'Planlama': 'Планирование',
    'Müşteri': 'Клиент',
    'Takım': 'Команда',
    'Risk': 'Риск',
    'Teknik': 'Техническое',
    'Süreç': 'Процесс',
    'Ürün': 'Продукт',
  },
}

const qEn: Record<number, string> = {
  1: 'What do you do first when a new project arrives?',
  2: 'How do you manage when the client keeps changing scope?',
  3: 'What do you do when there is a technical disagreement in the team?',
  4: 'What is your process when a critical bug hits production?',
  5: 'What do you consider when choosing technology?',
  6: 'How do you plan sprints?',
  7: 'How do you manage a remote team?',
  8: 'What do you do when a project deadline won\'t be met?',
  9: 'How does your code review process work?',
  10: 'How do you manage technical debt?',
  11: 'How do you onboard a new team member?',
  12: 'Microservice or monolith — how do you decide?',
  13: 'How does your CI/CD pipeline work?',
  14: 'How do you detect and solve performance issues?',
  15: 'How do you manage project documentation?',
  16: 'What is your approach to security?',
  17: 'How do you communicate with non-technical clients?',
  18: 'What is your test strategy?',
  19: 'What are the most common mistakes that make a project fail?',
  20: 'How do you measure product quality?',
  21: 'What do you focus on in database design?',
  22: 'Do you ever say "no" to a client?',
  23: 'How do you manage AI/ML projects differently from traditional software?',
  24: 'How do you keep team motivation high?',
  25: 'How do you manage multiple projects at once?',
}

const qRu: Record<number, string> = {
  1: 'Что вы делаете первым делом при новом проекте?',
  2: 'Как управлять постоянным изменением объёма работ клиентом?',
  3: 'Что делаете при техническом разногласии в команде?',
  4: 'Каков процесс при критическом баге в продакшене?',
  5: 'На что обращаете внимание при выборе технологий?',
  6: 'Как планируете спринты?',
  7: 'Как управляете удалённой командой?',
  8: 'Что делаете, если дедлайн не успеваете?',
  9: 'Как устроен процесс code review?',
  10: 'Как управляете техническим долгом?',
  11: 'Как вводите нового участника в проект?',
  12: 'Микросервисы или монолит — как решаете?',
  13: 'Как работает ваш CI/CD?',
  14: 'Как находите и решаете проблемы производительности?',
  15: 'Как ведёте проектную документацию?',
  16: 'Каков ваш подход к безопасности?',
  17: 'Как общаетесь с нетехническим клиентом?',
  18: 'Какова стратегия тестирования?',
  19: 'Какие ошибки чаще всего приводят к провалу проекта?',
  20: 'Как измеряете качество продукта?',
  21: 'На что обращаете внимание при проектировании БД?',
  22: 'Говорите ли вы клиенту «нет»?',
  23: 'Чем управление AI/ML‑проектом отличается от обычного?',
  24: 'Как поддерживаете мотивацию команды?',
  25: 'Как ведёте несколько проектов одновременно?',
}

const aEn: Record<number, string> = {
  1: 'First I sit with the client and understand what they need and why. Before diving into technical details, I solve the business problem in my mind. In Solar Analysis, the client said "I want panel monitoring" but the real need was reducing maintenance costs. Then with the team we define scope, determine the MVP, and plan sprints. The first week usually goes to research and PoC.',
  2: 'Scope creep happens in every project, it\'s normal. But it must be controlled. In OmniSell, the client wanted to add a new marketplace every week. We put in a change request process — we do impact analysis for each new request and share time/cost estimates. The client makes informed decisions. We have a priority matrix: urgent/important vs important/not urgent. We don\'t accept changes mid-sprint, they go to backlog.',
  3: 'First I listen to everyone\'s opinion. In Go-Trade there was a C++ DLL vs Go native debate. Everyone defended their preference. I said "let\'s write benchmarks, let data speak." We ran shared memory tests, C++ DLL approach was 10x faster. We made a data-driven decision, nobody was offended. If technically equivalent, we choose the tech the team is most comfortable with. Ego doesn\'t matter, project success does.',
  4: 'First 5 minutes: determine the scope — is it affecting users? In Hayalet Trading the named pipe bridge broke at 3am, all positions were open. Risk management kicked in immediately, positions auto-closed. Then root cause analysis — logs showed Windows update reset pipe handles. Hotfix shipped in 2 hours. Then postmortem, monitoring was added. Every critical bug must yield a lesson.',
  5: 'Three main criteria: 1) Fit for the problem — PosPro needed cross-platform, we chose Flutter. One codebase for web and mobile. 2) Team competency — putting unknown tech in production is risky. Learning time must fit within sprints. 3) Ecosystem maturity — in Hayalet we chose Go because concurrency support is excellent, perfect for trading bots. I don\'t chase hype, I prefer proven tech but I\'m not afraid of innovation.',
  6: 'We use 2-week sprints. In backlog grooming we assign story points — fibonacci (1,2,3,5,8,13). Anything above 8 gets broken down. We calculate sprint capacity — each developer has different velocity. In Indirim Kanallari there were 11 scrapers, each a separate story. We\'d fit 6-7 per sprint. We leave 20% buffer because every sprint has surprises. In retrospective we discuss what to improve.',
  7: 'We work trust-based. Daily standup 15 min — what did you do yesterday, what will you do today, any blockers? Async communication mainly, thread-based on Slack. Video calls only when needed. In Barter Qween we worked from 3 different cities. Every Friday there\'s a demo, everyone shows what they built. Code review is mandatory, at least 1 approval before PR merge. Transparency is key — everything documented in Notion.',
  8: 'Early detection is critical. We track weekly burndown charts. If the trend goes bad, we act immediately. In Diagnostic, the ML pipeline turned out more complex than expected. We transparently told the client, narrowed MVP scope — launched with 1 model instead of 3 but delivered a working product. Then iteratively added the others. Bad news delivered late is worse, good news early is better.',
  9: 'Every PR requires at least 1 reviewer. We have a review checklist: security, performance, readability, test coverage. In Sinav Analiz, Supabase RLS policies were especially carefully reviewed — security critical. In reviews be constructive, critique the code not the person. Instead of "this is wrong" say "this alternative might be more performant." We don\'t accept large PRs, if over 300 lines — break it down.',
  10: 'We allocate 15-20% of each sprint to tech debt payoff. We maintain a debt backlog — critical, medium, low. In Mandira Sut Takip, Firebase queries slowed down as data grew. We dedicated one story in the sprint to index optimization, query time dropped from 3 seconds to 200ms. Accumulating tech debt is like paying interest — the sooner you pay, the less pain.',
  11: 'We have an onboarding plan: day 1 project introduction, days 2-3 environment setup and architecture walkthrough, first week a small bug fix or feature. In FireAlert the new teammate opened their first PR on day 3. We use a buddy system — an experienced person accompanies the newcomer. Documentation is kept current, README must have a "quick start" section. We foster a culture of asking questions freely.',
  12: 'Start monolith, split as needed. OmniSell started as monolith, when marketplace count grew we moved each adapter to a separate service. Microservice overhead is too high for small teams. In Hayalet Trading we started as Go monolith but extracted agents via gRPC because each agent scaled at different rates. The decision depends on context — "it depends" is cliche but true.',
  13: 'Every project minimum: lint → test → build → deploy. In AdPro CLI with Go we use GitHub Actions — lint+test on push, multi-platform release build on tag. Vercel projects get automatic preview deploys, each PR gets its own URL. Indirim Kanallari uses Docker Compose, self-hosted via Coolify. Rollback must always be possible — we should be able to revert to previous version in 30 seconds.',
  14: 'Measure first, then optimize. In Solar Analysis v2 the dashboard was slow — Chrome DevTools profiler showed TimescaleDB queries were the bottleneck. Added indexes, optimized queries, put Grafana monitoring. We avoid premature optimization. In Hayalet Trading microseconds matter — we profile with Go pprof, named pipe latency is continuously monitored. Each project has different performance criteria.',
  15: 'Code should speak for itself? I disagree. README, API docs, architecture diagrams are essential. But don\'t write unnecessary docs — outdated documentation is harmful. In EstimatePro we keep ADRs (Architecture Decision Records) — why we chose X, what were alternatives. Descriptive function names over comments. Swagger/OpenAPI is mandatory for backend. Project wiki in Notion, kept minimal.',
  16: 'Security by design, not bolted on. In Epinera health project, HIPAA compliance was mandatory — end-to-end encryption, audit logging, role-based access designed from day one. We check OWASP Top 10 in every code review. Dependency audit runs weekly, npm audit / pip-audit. We pentest our own projects with Melkorstux toolkit. Environment variables for secret management, never hardcoded credentials.',
  17: 'I use analogies. In Mandira Sut Takip with farmers, instead of "database" I said "digital ledger", instead of "API" I said "automatic connection." Every meeting has a demo — visual communication is a thousand times more effective than verbal. No tech jargon, I talk about business outcomes: instead of "loads in 3 seconds" say "your customer sees the page without waiting." Weekly progress reports with screenshots.',
  18: 'Test pyramid: many unit tests, medium integration, few E2E. FireAlert has Detox E2E tests but they run slowly, only for critical flows. OmniSell has fast Vitest unit tests, automatic on every PR. We don\'t do TDD but test-first approach works for complex logic. 80% coverage target but we don\'t obsess over numbers — critical business rules must be 100% tested, UI helpers 50% is fine.',
  19: '1) Not defining scope clearly from the start — everyone understands differently. 2) Communication gaps — nobody says anything until the problem grows. 3) Ignoring tech debt — 6 months later every feature takes 3x longer. 4) Wrong tech choice — chasing hype with a stack the team doesn\'t know. In Video Factory the Electron/Tauri decision wasn\'t made early, 3 weeks lost. Now we finalize architecture decisions in week one.',
  20: 'Let metrics speak: crash rate, response time, user satisfaction. In Indirim Kanallari scraper success rate must be 95%+, auto-alert if drops. In PosPro we track sync success rate in offline-first architecture. User feedback is most important — in FitCheck beta feedback led us to completely redesign the form analysis feature. Code quality: SonarQube, ESLint strict config.',
  21: 'We invest time in schema design on day one. Normalization vs denormalization trade-off decided by use case. In Sinav Analiz we used Supabase relational model, curriculum-exam-student-result relationships are clear. In Hayalet Redis time-series because speed is critical in trading, relational data is secondary. Migrations always version-controlled, seed data ready for test environments. Index strategy based on query patterns.',
  22: 'Yes, I say "no" when needed but always offer an alternative. In Diagnostic the client said "let\'s serve all patient data from a public API" — security risk too high. We proposed a role-based API gateway instead, access control was achieved and client\'s need was met. It\'s not saying "no" but "we can\'t do this but we can do that." Sometimes we need to be realistic about deadlines too — saying "yes" to impossible work is worse.',
  23: 'ML projects have more uncertainty. Model training results can\'t be guaranteed — hard to say "I\'ll deliver this accuracy." In Diagnostic we tried 3 different models (1D-CNN, BiLSTM, Transformer), couldn\'t predict which would give best results. Sprints have research spikes. We use DVC for data versioning, MLflow for experiment tracking. In Aura AI, Whisper fine-tuning took 2 sprints — in traditional projects you\'d ship a feature in 2 sprints.',
  24: 'Three things: meaning, autonomy, growth. Everyone should know why their work matters. In Solar Analysis when I say "we\'re reducing solar energy costs" the team\'s eyes light up. Everyone should make decisions in their domain — I don\'t micromanage. I create learning opportunities in code reviews. We celebrate wins — in sprint demo I acknowledge good work publicly. Zero tolerance for toxic culture.',
  25: 'Context switching is expensive, I minimize it. I dedicate specific days of the week to each project. Currently I have 5+ active projects but each being in different phases helps — one in development, one in maintenance, one in planning. I use a priority matrix: ICT Ultra and Hayalet trading are live, they\'re priority. Lumora and Aura AI are in development, more flexible. Notion kanban board per project, daily todo list for planning the day.',
}

const aRu: Record<number, string> = {
  1: 'Сначала встречаюсь с клиентом, чтобы понять, что и зачем нужно. До технических деталей решаю бизнес-задачу в голове. В Solar Analysis клиент сказал «хочу мониторинг панелей», но реальная потребность — снижение затрат на обслуживание. Затем с командой определяем scope, MVP и планируем спринты. Первая неделя — обычно исследование и PoC.',
  2: 'Scope creep бывает в каждом проекте, это нормально. Но его нужно контролировать. В OmniSell клиент каждую неделю хотел новый маркетплейс. Ввели процесс change request — анализ влияния и оценка сроков/стоимости. Клиент принимает информированное решение. Есть матрица приоритетов: срочное/важное. Изменения посреди спринта не принимаем — в бэклог.',
  3: 'Сначала выслушиваю всех. В Go-Trade был спор: C++ DLL или нативный Go. Каждый отстаивал своё. Я предложил: «Напишем бенчмарк, пусть данные решат.» Провели тест shared memory, C++ DLL оказался в 10 раз быстрее. Решение на основе данных — никто не обиделся. Эго не важно, важен успех проекта.',
  4: 'Первые 5 минут: определить масштаб — затрагивает ли пользователей? В Hayalet Trading ночью разорвался named pipe bridge, все позиции остались открытыми. Риск-менеджмент среагировал автоматически, позиции закрылись. Затем root cause analysis — Windows-обновление сбросило pipe handles. Hotfix за 2 часа. Потом постмортем и мониторинг. Каждый критический баг — урок.',
  5: 'Три критерия: 1) Соответствие задаче — PosPro нужен кроссплатформ, выбрали Flutter. 2) Компетенция команды — неизвестный стек в продакшене — риск. 3) Зрелость экосистемы — в Hayalet выбрали Go за concurrency. Не гонюсь за хайпом, но и инноваций не боюсь.',
  6: 'Двухнедельные спринты. Grooming со story points по Фибоначчи. Более 8 — разбиваем. Считаем capacity каждого. В Indirim Kanallari — 11 скраперов, по 6-7 в спринт. 20% буфер. Ретроспектива — что улучшить.',
  7: 'Работаем на доверии. Стендап 15 мин ежедневно. Асинхронная коммуникация через Slack. Видео-созвоны только по необходимости. В Barter Qween работали из 3 городов. Демо по пятницам. Code review обязателен. Прозрачность — всё документируется в Notion.',
  8: 'Раннее обнаружение критично. Отслеживаем burndown-диаграммы. В Diagnostic ML-пайплайн оказался сложнее ожидаемого. Честно сказали клиенту, сузили MVP — выпустили с 1 моделью вместо 3, но рабочий продукт. Потом итеративно добавили остальные.',
  9: 'Каждый PR — минимум 1 ревьюер. Чеклист: безопасность, производительность, читаемость, покрытие тестами. В Sinav Analiz — RLS-политики Supabase ревьюились особенно тщательно. Конструктивный подход: критикуем код, не человека. Большие PR (300+ строк) не принимаем — разбивай.',
  10: '15-20% каждого спринта на выплату тех. долга. Бэклог долга: критический/средний/низкий. В Mandira Sut Takip Firebase-запросы тормозили при росте данных. Выделили одну стори на оптимизацию индексов — запросы ускорились с 3с до 200мс.',
  11: 'Есть план онбординга: 1 день — знакомство с проектом, 2-3 — настройка среды и обзор архитектуры, первая неделя — небольшой багфикс. В FireAlert новичок открыл первый PR на 3 день. Buddy-система. Актуальная документация с quick start.',
  12: 'Начинаем с монолита, разделяем по мере необходимости. OmniSell начинал монолитом, при росте маркетплейсов — каждый адаптер стал отдельным сервисом. В Hayalet Go-монолит, но агенты вынесены через gRPC. Решение зависит от контекста.',
  13: 'Минимум в каждом проекте: lint → test → build → deploy. AdPro CLI: GitHub Actions — lint+test на push, мультиплатформенный релиз по тегу. Vercel-проекты — автоматический preview deploy на каждый PR. Rollback за 30 секунд обязателен.',
  14: 'Сначала измеряй, потом оптимизируй. В Solar Analysis v2 дашборд тормозил — профайлер показал bottleneck в TimescaleDB-запросах. Добавили индексы, оптимизировали, поставили Grafana-мониторинг. В Hayalet — микросекунды важны, Go pprof постоянно.',
  15: 'Код должен говорить за себя? Не согласен. README, API docs, диаграммы архитектуры — must have. Но не пишите лишнего — устаревшая документация вредна. В EstimatePro ведём ADR. Swagger/OpenAPI обязателен для бэкенда.',
  16: 'Security by design. В Epinera — HIPAA: end-to-end encryption, audit logging, RBAC с первого дня. OWASP Top 10 в каждом code review. Еженедельный dependency audit. Пентестим свои проекты Melkorstux. Секреты — только env vars.',
  17: 'Использую аналогии. В Mandira Sut Takip фермерам говорил «цифровая книга» вместо «база данных». На каждой встрече демо. Без жаргона, говорю о бизнес-результатах. Еженедельные отчёты со скриншотами.',
  18: 'Пирамида тестирования: много юнит, средне интеграционных, мало E2E. FireAlert — Detox для критических потоков. OmniSell — быстрые Vitest-тесты на каждый PR. Цель 80% покрытия, но критичная бизнес-логика — 100%.',
  19: '1) Нечёткий scope с начала. 2) Пробелы в коммуникации. 3) Игнорирование тех. долга. 4) Неправильный выбор технологий. В Video Factory решение Electron/Tauri затянулось — 3 недели потеряно. Теперь архитектурные решения фиксируем на первой неделе.',
  20: 'Метрики: crash rate, response time, удовлетворённость. В Indirim Kanallari success rate скраперов 95%+, автоалерт. В PosPro — sync success в offline-first. Обратная связь пользователей — в FitCheck полностью переделали фичу по фидбеку бета-тестеров.',
  21: 'Инвестируем время в проектирование схемы с первого дня. Нормализация vs денормализация — по use case. В Sinav Analiz — реляционная модель Supabase. В Hayalet — Redis time-series, скорость критична. Миграции под контролем версий.',
  22: 'Да, говорю «нет», но с альтернативой. В Diagnostic клиент хотел публичное API с данными пациентов — высокий риск. Предложили role-based API gateway. Не «нет», а «это нельзя, но можно вот так».',
  23: 'В ML-проектах больше неопределённости. Результат обучения не гарантирован. В Diagnostic пробовали 3 модели (1D-CNN, BiLSTM, Transformer). Спринты с research spike. DVC для данных, MLflow для экспериментов. Fine-tuning Whisper в Aura AI занял 2 спринта.',
  24: 'Три вещи: смысл, автономия, рост. В Solar Analysis «мы снижаем стоимость солнечной энергии» — глаза команды загораются. Каждый принимает решения в своей области. Признание успехов публично. Нулевая толерантность к токсичности.',
  25: 'Context switching дорого, минимизирую. Определённые дни недели — определённым проектам. 5+ активных проектов, но в разных фазах. ICT Ultra и Hayalet — в продакшене, приоритет. Lumora и Aura AI — в разработке, гибче. Kanban в Notion, ежедневный todo.',
}

export function getInterviewAnswers(locale: Locale): InterviewAnswer[] {
  if (locale === 'tr') return interviewAnswers
  const qMap = locale === 'en' ? qEn : qRu
  const aMap = locale === 'en' ? aEn : aRu
  return interviewAnswers.map((item) => ({
    ...item,
    question: qMap[item.questionNumber] ?? item.question,
    answer: aMap[item.questionNumber] ?? item.answer,
    category: categoryMap[locale][item.category] ?? item.category,
  }))
}
